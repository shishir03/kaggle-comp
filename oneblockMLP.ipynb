{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710670\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('archive/train.csv')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Drop irrelevant columns (TRIP_ID, TAXI_ID, etc.)\n",
    "# Encode categorical variables (CALL_TYPE, DAY_TYPE)\n",
    "# Handle missing values (ORIGIN_CALL, ORIGIN_STAND)\n",
    "preprocessed_data = train_data.drop(['TRIP_ID', 'DAY_TYPE', 'MISSING_DATA'], axis=1)\n",
    "\n",
    "preprocessed_data = pd.get_dummies(preprocessed_data, columns=['CALL_TYPE'])\n",
    "preprocessed_data['CALL_TYPE'] = preprocessed_data['CALL_TYPE_A'].astype(int) + preprocessed_data['CALL_TYPE_B'].astype(int) * 2 + preprocessed_data['CALL_TYPE_C'].astype(int) * 3\n",
    "preprocessed_data = preprocessed_data.drop(['CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C'], axis=1)\n",
    "\n",
    "preprocessed_data['ORIGIN_CALL'].fillna(0, inplace=True)\n",
    "preprocessed_data['ORIGIN_STAND'].fillna(0, inplace=True)\n",
    "\n",
    "preprocessed_data['TAXI_ID'] = preprocessed_data['TAXI_ID'] - 20000000  # Normalize taxi IDs\n",
    "\n",
    "preprocessed_data['TIMESTAMP'] = pd.to_datetime(preprocessed_data['TIMESTAMP'], unit='s')\n",
    "preprocessed_data['HOUR'] = preprocessed_data['TIMESTAMP'].dt.hour\n",
    "preprocessed_data['DAY_OF_WEEK'] = preprocessed_data['TIMESTAMP'].dt.dayofweek\n",
    "preprocessed_data['MONTH'] = preprocessed_data['TIMESTAMP'].dt.month\n",
    "#preprocessed_data['YEAR'] = preprocessed_data['TIMESTAMP'].dt.year\n",
    "preprocessed_data = preprocessed_data.drop('TIMESTAMP', axis=1)\n",
    "\n",
    "X = preprocessed_data.drop(['POLYLINE'], axis=1)\n",
    "y = train_data['POLYLINE'].str.count(',') * 15  # Calculate travel time in seconds\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ORIGIN_CALL  ORIGIN_STAND  TAXI_ID  CALL_TYPE  HOUR  DAY_OF_WEEK  \\\n",
      "8149          6534.0           0.0      198          1    17            1   \n",
      "825853           0.0           0.0      664          3    17            0   \n",
      "896733           0.0          27.0      424          2    13            3   \n",
      "29112            0.0           9.0      492          2    19            5   \n",
      "767655           0.0           0.0      476          3     4            4   \n",
      "...              ...           ...      ...        ...   ...          ...   \n",
      "259178       24662.0           0.0      184          1    18            2   \n",
      "1414414          0.0          37.0       83          2    10            6   \n",
      "131932           0.0          25.0      600          2    19            6   \n",
      "671155           0.0          25.0      451          2    16            4   \n",
      "121958           0.0           0.0      342          2    14            4   \n",
      "\n",
      "         MONTH  \n",
      "8149         7  \n",
      "825853      12  \n",
      "896733       1  \n",
      "29112        7  \n",
      "767655      12  \n",
      "...        ...  \n",
      "259178       8  \n",
      "1414414      5  \n",
      "131932       7  \n",
      "671155      11  \n",
      "121958       7  \n",
      "\n",
      "[1539603 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.size(1)\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_X, batch_y \u001b[39m=\u001b[39m X_train_tensor[indices], y_train_tensor[indices]\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m output \u001b[39m=\u001b[39m model(batch_X)\n\u001b[1;32m     13\u001b[0m loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39msqueeze(), batch_y)\n\u001b[1;32m     15\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[73], line 12\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m batch_size \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_hidden(batch_size)\n\u001b[0;32m---> 12\u001b[0m out, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x, hidden)\n\u001b[1;32m     13\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:445\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m hx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m         \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[39m{\u001b[39;00mhx\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    447\u001b[0m         hx \u001b[39m=\u001b[39m hx\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X_train_tensor.size(0))\n",
    "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_X, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "        batch_X = batch_X.unsqueeze(1)  # Add an extra dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output.squeeze(), batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_tensor)\n",
    "        val_loss = criterion(val_output.squeeze(), y_val_tensor)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1868750.0\n",
      "[[1302.2462]\n",
      " [1440.9738]\n",
      " [1412.7057]\n",
      " ...\n",
      " [1265.7263]\n",
      " [1395.9257]\n",
      " [1355.259 ]]\n",
      "Validation RMSE: 1367.0224058973524\n"
     ]
    }
   ],
   "source": [
    "# Convert the validation data to tensors\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val_tensor)\n",
    "    val_loss = criterion(val_predictions, y_val_tensor)\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# Convert the predictions back to numpy arrays\n",
    "val_predictions = val_predictions.cpu().numpy()\n",
    "print(val_predictions)\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) on the validation data\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "print(f\"Validation RMSE: {val_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
